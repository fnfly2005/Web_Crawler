{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不是一直都要用锤子\n",
    "beautifulsoup4 BeautifulSoup b.find_all()  \n",
    "beautifulsoup4 BeautifulSoup b.find()  \n",
    "python 更多控制流工具 Lambda表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 假如不加思考直接写出下面这样一行代码来抽取内容\n",
    " bsObj.findAll(\"table\")[4].findAll(\"tr\")[2].find(\"td\").findAll(\"div\")[1].find(\"a\")\n",
    " 虽然也可以达到目标,但这样看起来并不是很好\n",
    " 当网站管理员稍作修改，这行代码就会失效\"\"\"\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "def getText(url,fuc):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(html.read())\n",
    "        text = fuc(bsObj)\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return text\n",
    "f1 = lambda b:b.find_all(\"body\")[0].find(\"div\")\n",
    "text = getText(\"http://pythonscraping.com/pages/page1.html\",f1)\n",
    "if text == None:\n",
    "    print(\"Title could not be found\")\n",
    "else:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再端一碗BeautifulSoup\n",
    "beautifulsoup4 BeautifulSoup b.get_text()  \n",
    "beautifulsoup4 BeautifulSoup b.find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(b):\n",
    "    nameList=b.find_all(name=\"span\",attrs={\"class\":\"green\"})\n",
    "    for name in nameList:\n",
    "        print(name.get_text())\n",
    "getText(\"http://pythonscraping.com/pages/warandpeace.html\",f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup的find()和findAll()\n",
    "beautifulsoup4 BeautifulSoup b.find_all() text  \n",
    " beautifulsoup4 BeautifulSoup b.find_all() keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(b):\n",
    "    nameList = b.find_all(text=\"the prince\")\n",
    "    print(nameList)\n",
    "getText(\"http://pythonscraping.com/pages/warandpeace.html\",f3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f4(b):\n",
    "    allText = b.find_all(id=\"text\")\n",
    "    print(allText[0].get_text())\n",
    "\n",
    "getText(\"http://pythonscraping.com/pages/warandpeace.html\",f4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他BeautifulSoup对象\n",
    "BeautifulSoup对象  \n",
    "NavigableString对象  \n",
    "Comment对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导航树\n",
    "##### 处理子标签和其他后代标签\n",
    "beautifulsoup4 Tag对象 t.children "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f5(b):   \n",
    "    #打印giftList表格中所有产品的数据行\n",
    "    for child in b.find(\"table\",{\"id\":\"giftList\"}).children:\n",
    "        print(child)\n",
    "getText(\"http://pythonscraping.com/pages/page3.html\",f5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 处理兄弟标签\n",
    "beautifulsoup4 Tag对象 t.next_siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f6(b):\n",
    "    #打印产品列表里的所有行的产品\n",
    "    for sibling in b.find(\"table\",{\"id\":\"giftList\"}).tr.next_siblings:\n",
    "        print(sibling)\n",
    "getText(\"http://pythonscraping.com/pages/page3.html\",f6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 父标签处理\n",
    "beautifulsoup4 Tag对象 t.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "结构图示\n",
    "<tr>\n",
    "    --<td>\n",
    "    --</td>\n",
    "    --<td>\n",
    "        --\"$15.00\"\n",
    "    --</td>\n",
    "    --<td>\n",
    "        --<img src=\"../img/gifts/img1.jpg\">\n",
    "    --</td>\n",
    "\"\"\"\n",
    "def f7(b):\n",
    "    #抓取/img/gifts/img1.jpg 这个图片对应商品的价格\n",
    "    print(b.find(\"img\",{\"src\":\"../img/gifts/img1.jpg\"}).parent.previous_sibling.get_text())\n",
    "getText(\"http://pythonscraping.com/pages/page3.html\",f7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则表达式\n",
    "# 正则表达式和BeautifulSoup\n",
    "python re re.compile()  \n",
    "python re Regular Expression Objects  \n",
    "beautifulsoup4 BeautifulSoup 正则表达式过滤器 Regular Expression Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def f8(b):\n",
    "    #抓取所有图片的URL连接，但要排除多余的图片(logo 空白图片 隐藏图片 图片标签)\n",
    "    images = b.find_all(\"img\",{\"src\":re.compile(\"\\.\\.\\/img\\/gifts/img.*\\.jpg\")})\n",
    "    for image in images:\n",
    "        print(image[\"src\"])\n",
    "getText(\"http://pythonscraping.com/pages/page3.html\",f8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取属性\n",
    "beautifulsoup4 Tag对象 t.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f9(b):\n",
    "    #抓取图片的资源位置src\n",
    "    for image in b.find_all(\"img\"):\n",
    "        print(image.attrs[\"src\"])\n",
    "getText(\"http://pythonscraping.com/pages/page3.html\",f9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda表达式\n",
    "beautifulsoup4 BeautifulSoup 方法过滤器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f10(b):  \n",
    "    print(b.find_all(lambda tag:len(tag.attrs) ==2))\n",
    "getText(\"http://pythonscraping.com/pages/page3.html\",f10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
