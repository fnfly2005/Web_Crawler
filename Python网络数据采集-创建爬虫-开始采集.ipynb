{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 遍历单个域名\n",
    "python urllib.request u.urlopen()  \n",
    "beautifulsoup4 BeautifulSoup BeautifulSoup()  \n",
    "python re re.compile()  \n",
    "python random r.randint()  \n",
    "beautifulsoup4 Tag对象 t.attrs  \n",
    "python random r.seed()  \n",
    "python datetime datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,re,random,datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = {\n",
    "    'http':'socks5://127.0.0.1:1080',\n",
    "    'https':'socks5://127.0.0.1:1080'\n",
    "}\n",
    "r = requests.get(\"https://en.wikipedia.org/wiki/Kevin_Bacon\", proxies=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsObj = BeautifulSoup(r.text)\n",
    "for link in bsObj.find_all(\"a\"):\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex =re.compile(\"^(/wiki/)((?!:).)*$\")\n",
    "for link in bsObj.find(\"div\",{\"id\":\"bodyContent\"}).find_all(\"a\",href=regex):\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(datetime.datetime.now())\n",
    "def getLinks(articleUrl):\n",
    "    r = requests.get(\"https://en.wikipedia.org\"+articleUrl, proxies=proxies)\n",
    "    bsObj = BeautifulSoup(r.text)\n",
    "    return bsObj.find(\"div\",{\"id\":\"bodyContent\"}).find_all(\"a\",href=regex)\n",
    "links = getLinks(\"/wiki/Kevin_Bacon\")\n",
    "n=0\n",
    "while len(links)>0:\n",
    "    newArticle = links[random.randint(0,len(links)-1)].attrs[\"href\"]\n",
    "    print(newArticle)\n",
    "    links =getLinks(newArticle)\n",
    "    n=n+1\n",
    "    if n ==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采集整个网站\n",
    "python Built-in Functions set()  \n",
    "beautifulsoup4 BeautifulSoup b.get_text()  \n",
    "beautifulsoup4 BeautifulSoup b.find()  \n",
    "python The global statement The global statement  \n",
    "beautifulsoup4 Tag对象 t.attrs  \n",
    "python Comparisons  in and not in  \n",
    "python re re.compile()  \n",
    "python set s.add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def getLinks(pageUrl):\n",
    "    global pages\n",
    "    html = requests.get(\"https://en.wikipedia.org\"+pageUrl, proxies=proxies)\n",
    "    bsObj = BeautifulSoup(html.text)\n",
    "    try:\n",
    "        print(bsObj.h1.get_text())\n",
    "        print(bsObj.find(id=\"mw-content-text\").find_all(\"p\")[0]) \n",
    "        print(bsObj.find(id=\"ca-edit\").find(\"span\").find(\"a\").attrs['href']) \n",
    "    except AttributeError:\n",
    "        print(\"页面缺少一些属性！不过不用担心\")\n",
    "    for link in bsObj.find_all(\"a\",href=re.compile(\"^(/wiki/)\")):\n",
    "        if 'href' in link.attrs:\n",
    "            if link.attrs['href'] not in pages:\n",
    "            #我们遇到了新页面\n",
    "                newPage = link.attrs['href']\n",
    "                print(\"------------------\\n\"+newPage)            \n",
    "                pages.add(newPage)\n",
    "                getLinks(newPage)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = set()\n",
    "html = requests.get(\"https://en.wikipedia.org\", proxies=proxies)\n",
    "bsObj = BeautifulSoup(html.text)\n",
    "try:\n",
    "    print(bsObj.h1.get_text())\n",
    "    print(bsObj.find(id=\"mw-content-text\").find_all(\"p\")[0])#页面-正文模块-正文\n",
    "except AttributeError:\n",
    "    print(\"页面缺少一些属性！不过不用担心\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #词条页面-顶部导航模块-右侧编辑Edit标签tab\n",
    "    print(bsObj.find(id=\"ca-edit\").find(\"span\").find(\"a\").attrs['href'])\n",
    "except AttributeError:\n",
    "    print(\"页面缺少一些属性！不过不用担心\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex=re.compile(\"^(/wiki/)\")\n",
    "link = bsObj.find_all(\"a\",href=regex)[0]\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('href' in link.attrs)\n",
    "print(link.attrs['href'] not in pages)\n",
    "newPage = link.attrs['href']\n",
    "print(\"------------------\\n\"+newPage)\n",
    "pages.add(newPage)\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过互联网采集\n",
    "python Built-in Functions set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages=set()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
